{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backprop Workbook 01\n",
    "\n",
    "**For these questions, assume that an $x$ input has 1024 dimensions, that the first hidden layer should have $512$ units, a second layer has $256$ units, and that there are $10$ classes to choose from at the end.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cell to run for Latex commands**\n",
    "\n",
    "\\\\[\n",
    "\\newcommand{\\fpartial}[2]{\\frac{\\partial #1}{\\partial #2}}\n",
    "\\newcommand{\\grad}[1]{\\nabla #1}\n",
    "\\newcommand{\\softmax}[0]{\\text{SOFTMAX}}\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. What is $\\fpartial{}{x} \\log x$?**\n",
    "\n",
    "$\\frac{1}{x}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. What is $\\fpartial{}{x} e^x$?**\n",
    "\n",
    "$e^x$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. What is $\\fpartial{}{x} e^{(x^2)}$?**\n",
    "\n",
    "$2x e^x$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. What rule did we apply?**\n",
    "\n",
    "Chain rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Explain the chain rule. Given functions $f$ and $g$, write a function for the derivative of the composition function $f \\circ g$ where $(f \\circ g)(x) = f(g(x))$.**\n",
    "\n",
    "\\\\[\n",
    "(f \\circ g)'(x)\n",
    "=\n",
    "f'(g(x))g'(x)\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation: The Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent is about changing the weight matrices $W^{(i)}$ and the bias vectors $b^{(i)}$ so that the loss goes down. To do this, we need to know how the loss changes as we change the weight matrices and bias vectors.\n",
    "\n",
    "That means we need to calculate gradients like $\\grad_{W^{(i)}} CE(h^{(3)}, y)$ and $\\grad_{b^{(i)}} CE(h^{(3)}, y)$.\n",
    "\n",
    "**1. What is the shape of $\\grad_{W^{(3)}} CE(h^{(3)}, y)$? What does the entry at position $(i, j)$ of this matrix represent?**\n",
    "\n",
    "The shape is $(256, 10)$. The entry at position $(i, j)$ represents how changing $W^{(3)}_{i, j}$ would change the loss $CE(h^{(3)}, y)$. That is:\n",
    "\n",
    "\\\\[\n",
    "\\left(\n",
    "    \\grad_{W^{(3)}} CE(h^{(3)}, y)\n",
    "\\right)_{i, j}\n",
    "=\n",
    "\\fpartial{}{W^{(3)}_{i, j}}\n",
    "CE(h^{(3)}, y)\n",
    "\\\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. How is it that changing a weight in $W^{(3)}$ might change the loss?**\n",
    "\n",
    "A change to $W^{(3)}_{i, j}$ changes $z^{(3)}_j$, which changes all the $h^{(3)}$ values. Since that changes the probability of the correct class $h^{(3)}_{y^*}$, this will change the cross entropy loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation to $z^{(3)}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to calculate $\\grad_{W^{(3)}} CE(h^{(3)}, y)$, we will first calculate $\\grad_{z^{(3)}} CE(h^{(3)}, y)$. Once we know how changing $z^{(3)}$ changes the cross entropy, we can then think about how changing $W^{(3)}$ changes $z^{(3)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. What is the shape of $\\grad_{z^{(3)}} CE(h^{(3)}, y)$? What does each entry represent?**\n",
    "\n",
    "The shape is $(10,)$. Each entry represents how a change in $z^{(3)}_i$ would change the loss. Formula-wise this is:\n",
    "\n",
    "\\\\[\n",
    "\\left(\n",
    "    \\grad_{z^{(3)}} CE(h^{(3)}, y)\n",
    "\\right)_i\n",
    "=\n",
    "\\fpartial{}{z^{(3)}_i}\n",
    "CE(h^{(3)}, y)\n",
    "\\\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Recall that $h^{(3)} = \\text{SOFTMAX}\\left(z^{(3)}\\right)$. So before anything, let's write $CE_\\text{vector}(h^{(3)}, y)$ in terms of the $z^{(3)}_i$ values by expanding the formulas for cross-entropy and for $h^{(3)}$.**\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "    CE\\left(h^{(3)}, y\\right)\n",
    "&=\n",
    "    -\\log h^{(3)} \\cdot y\n",
    "\\\\\n",
    "&=\n",
    "    -\\log \\sum_{i = 0}^{9} h^{(3)}_i y_i\n",
    "\\\\\n",
    "&=\n",
    "    -\\log \\sum_{i = 0}^{9}\n",
    "        y_i\n",
    "        \\frac{\n",
    "            \\exp\\left(z^{(3)}_i\\right)\n",
    "        }{\n",
    "            \\sum_{j=0}^9\n",
    "            \\exp\\left(z^{(3)}_j\\right)\n",
    "        }\n",
    "\\end{align}\n",
    "\\\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**2. Only one term of the sum above matters. Which one? Why? Write the formula without the summation.**\n",
    "\n",
    "The only term that matters is for $i = y^*$. That's because only the probability on the correct class matters.\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "    CE\\left(h^{(3)}, y\\right)\n",
    "&=\n",
    "    -\\log \\sum_{i = 0}^{9}\n",
    "        y_i\n",
    "        \\frac{\n",
    "            \\exp\\left(z^{(3)}_i\\right)\n",
    "        }{\n",
    "            \\sum_{j=0}^9\n",
    "            \\exp\\left(z^{(3)}_j\\right)\n",
    "        }\n",
    "\\\\\n",
    "&=\n",
    "    -\\log\\left(\n",
    "        y_{y^*}\n",
    "        \\frac{\n",
    "            \\exp\\left(z^{(3)}_{y^*}\\right)\n",
    "        }{\n",
    "            \\sum_{j=0}^9\n",
    "            \\exp\\left(z^{(3)}_j\\right)\n",
    "        }\n",
    "    \\right)\n",
    "\\\\\n",
    "&=\n",
    "    -\\log\\left(\n",
    "        \\frac{\n",
    "            \\exp\\left(z^{(3)}_{y*}\\right)\n",
    "        }{\n",
    "            \\sum_{j=0}^9\n",
    "            \\exp\\left(z^{(3)}_j\\right)\n",
    "        }\n",
    "    \\right)\n",
    "\\end{align}\n",
    "\\\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Why are all the $z^{(3)}$ values still present in the formula?**\n",
    "\n",
    "Because they are all part of the softmax calculation because they represents odds relative to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Write this log in terms of a difference of logs.**\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "    CE\\left(h^{(3)}, y\\right)\n",
    "&=\n",
    "    -\\log\\left(\n",
    "        \\frac{\n",
    "            \\exp\\left(z^{(3)}_{y*}\\right)\n",
    "        }{\n",
    "            \\sum_{j=0}^9\n",
    "            \\exp\\left(z^{(3)}_j\\right)\n",
    "        }\n",
    "    \\right)\n",
    "\\\\\n",
    "&=\n",
    "    -\\log \\left(\\exp\\left(z^{(3)}_{y*}\\right)\\right)\n",
    "    +\n",
    "    \\log \\left(\\sum_{j=0}^9 \\exp\\left(z^{(3)}_j\\right)\\right)\n",
    "\\\\\n",
    "&=\n",
    "    -z^{(3)}_{y*}\n",
    "    +\n",
    "    \\log \\left(\\sum_{j=0}^9 \\exp\\left(z^{(3)}_j\\right)\\right)\n",
    "\\end{align}\n",
    "\\\\]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. We're trying to calculate $\\grad_{z^{(3)}} CE(h^{(3)}, y)$. That means calculating each partial derivative $\\fpartial{}{z^{(3)}_i} CE(h^{(3)}, y)$. What is the partial of the first term when $i \\ne y^*$? What is the partial of the first term when $i = y^*$?**\n",
    "\n",
    "The first term is just $-z^{(3)}_{y*}$, so if we differentiate with respect to some $z^{(3)}_i$ where $i$ is *not* the correct class, then this derivative is zero.\n",
    "\n",
    "Otherwise, the derivative is $-1$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Why is this term zero sometimes? Why is it negative sometimes?**\n",
    "\n",
    "This is saying that changing the $z^{(3)}_i$ values for the wrong classes doesn't change the numerator. But when you change it for the *right* class, it changes the numerator, which increases the probability of the correct class, which reduces the cross-entropy loss.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Now the second term! Using the rule that the derivative of $\\log a$ wrt $a$ is $1/a$, and also the chain rule, do the first-step of the deriative of the second term wrt $z^{(3)}_i$.**\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "    \\fpartial{}{z^{(3)}_i}\n",
    "        \\log \\left(\\sum_{j=0}^9 \\exp\\left(z^{(3)}_j\\right)\\right)\n",
    "&=\n",
    "    \\frac{1}{\\sum_{j=0}^9 \\exp\\left(z^{(3)}_j\\right)}\n",
    "    \\fpartial{}{z^{(3)}_i}\n",
    "        \\left(\\sum_{j=0}^9 \\exp\\left(z^{(3)}_j\\right)\\right)\n",
    "\\end{align}\n",
    "\\\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Next, use the rule that the derivative of $e^a$ wrt $a$ is also $e^a$. Also eliminate unnecessary terms in the sum.**\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "    \\frac{1}{\\sum_{j=0}^9 \\exp\\left(z^{(3)}_j\\right)}\n",
    "    \\fpartial{}{z^{(3)}_i}\n",
    "        \\left(\\sum_{j=0}^9 \\exp\\left(z^{(3)}_j\\right)\\right)\n",
    "&=\n",
    "    \\frac{1}{\\sum_{j=0}^9 \\exp\\left(z^{(3)}_j\\right)}\n",
    "    \\exp\\left(z^{(3)}_i\\right)\n",
    "\\end{align}\n",
    "\\\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. Finally, use the definition of $h^{(3)}_i = SOFTMAX(z^{(3)})_i$ to simplify this.**\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "    \\frac{1}{\\sum_{j=0}^9 \\exp\\left(z^{(3)}_j\\right)}\n",
    "    \\exp\\left(z^{(3)}_i\\right)\n",
    "&=\n",
    "    h^{(3)}_i\n",
    "\\end{align}\n",
    "\\\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10. Why is the partial of the second term the same formula no matter whether $i$ is $y^*$?**\n",
    "\n",
    "Because the second term is about the change to the denominator, and you change the denominator regardless of whether you are changing the correct class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11. Give the overall formula for the partial when $i \\ne y^*$ and for $i = y^*$.**\n",
    "\n",
    "$h^{3}_i$ and $-1.0 + h^{3}_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12. Let's use these to write the gradient as a vector formula. Note that you want to subtract $1.0$ from exactly one term of $h^{(3)}$ and nothing from the rest...**\n",
    "\n",
    "$h^{(3)} - y$.\\\\[\n",
    "\\grad_{z^{(3)}} CE(h^{(3)}, y)\n",
    "=\n",
    "h^{(3)} - y\n",
    "\\\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**13. Let's do an intuition check. What entries of the gradient are positive? Which are negative? Why?**\n",
    "\n",
    "All entries except $y^*$ are positive, because increasing their log odds decreases the probability on the right answer. That increases the loss.\n",
    "\n",
    "Increasing $z^{(3)}_{y^*}$ increases the probability of the correct answer, so it reduces the loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backprop to $W^{(3)}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. To update the weights $W^{(3)}$ we must calculate $\\grad_{W^{(3)}} CE(h^{(3)}, y)$. What is the shape of this \"2 dimensional gradient\"?**\n",
    "\n",
    "$(256, 10)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. What does each entry $\\left(\\grad_{W^{(3)}} CE(h^{(3)}, y)\\right)_{i, j}$ mean?**\n",
    "\n",
    "It means how much the loss will change if we changed $W_{i, j}$ a little.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Which value in the second hidden layer does $W_{i, j}$ connect to which pre-activation in the third layer?**\n",
    "\n",
    "$h^{(2)}_i$ to $z^{(3)}_j$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. If for a given $j$ we have $\\fpartial{}{z^{(3)}_j} CE(h^{(3)}, y)$ is zero, what is $\\grad_{W^{(3)}} CE(h^{(3)}, y)$ for all $(i, j)$ for all $i$ and our given $j$? Why?**\n",
    "\n",
    "It must be zero. Because changing any $W_{i, j}$ may change $z^{(3)}_j$, but we know that has no impact on the loss.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. If for a given $i$ we have $h^{(2)}_i = 0$, what is $\\grad_{W^{(3)}} CE(h^{(3)}, y)$ for all $(i, j)$ for all $j$ and our given $i$? Why?**\n",
    "\n",
    "It must be zero. Changing any $W_{i, j}$ won't change $z^{(3)}_j$, because $z^{(3)}_j$ is a weighted sum of the $h^{(2)}$ values. If $h^{(2)}_i$ is zero, changing the associated weight doesn't change $z^{(3)}_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Given the above, what two \"forces\" does $\\left(\\grad_{W^{(3)}} CE(h^{(3)}, y)\\right)_{i, j}$ need to combine?**\n",
    "\n",
    "First, the amount that changing $W^{(3)}_{i, j}$ changes $z^{(3)}_j$.\n",
    "\n",
    "Second, the amount that changing $z^{(3)}_j$ changes the loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Apply the chain rule to $\\fpartial{}{W^{(3)}_{i, j}} CE(h^{(3)}, y)$. Break this up into (a) how does $W^{(3)}_{i, j}$ change $h^{(3)}_j$ and (b) how does $h^{(3)}_j$ change the cross-entropy. Write a product of two partials, but you don't need to evaluate the partials.**\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "\\fpartial{}{W^{(3)}_{i, j}} CE(h^{(3)}, y)\n",
    "&=\n",
    "\\left(\n",
    "    \\fpartial{}{W^{(3)}_{i, j}} z^{(3)}_j\n",
    "\\right)\n",
    "\\left(\n",
    "    \\fpartial{}{z^{(3)}_j} CE(h^{(3)}, y)\n",
    "\\right)\n",
    "\\end{align}\n",
    "\\\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. We must calculate $\\fpartial{}{W^{(3)}_{i, j}} z^{(3)}_j$. What is it? Use the formula for $z^{(3)}_j$.**\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "    \\fpartial{}{W^{(3)}_{i, j}} z^{(3)}_j\n",
    "&=\n",
    "    \\fpartial{}{W^{(3)}_{i, j}} \\sum_{i=0}^{256} h^{(2)}_i W_{i, j}\n",
    "\\\\\n",
    "&=\n",
    "    h^{(2)}_i\n",
    "\\end{align}\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. We calculated $\\fpartial{}{z^{(3)}_j} CE(h^{(3)}, y)$ before. What is it?**\n",
    "\n",
    "\\\\[\n",
    "(h^{(3)} - y)_j\n",
    "\\\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10. Using the last two answers, what is $\\fpartial{}{W^{(3)}_{i, j}} CE(h^{(3)}, y)$ then?**\n",
    "\n",
    "\\\\[\n",
    "\\fpartial{}{W^{(3)}_{i, j}} CE(h^{(3)}, y)\n",
    "=\n",
    "    h^{(2)}_i\n",
    "    (h^{(3)} - y)_j\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11. We want $\\grad_{W^{(3)}} CE(h^{(3)}, y)$, which is a matrix. Each entry of the matrix consists of a product of two factors as above. What is the first factor for every entry in row $i$?**\n",
    "\n",
    "$h^{(2)}_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11. What is the second factor for every entry in column $j$?**\n",
    "\n",
    "$(h^{(3)} - y)_j$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12. If a vector $u$ has length $a$ and a vector $v$ has length $b$, what is the *outer product* $u \\otimes v$? What is its shape?**\n",
    "\n",
    "The shape is $(a, b)$ and entry $(i, j)$ is equal to $u_i v_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**13. Can you write $\\grad_{W^{(3)}} CE(h^{(3)}, y)$ as an outer product of two vectors?**\n",
    "\n",
    "\\\\[\n",
    "\\grad_{W^{(3)}} CE(h^{(3)}, y)\n",
    "=\n",
    "h^{(2)} \\otimes (h^{(3)} - y)\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (default)",
   "language": "python",
   "name": "conda-default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
