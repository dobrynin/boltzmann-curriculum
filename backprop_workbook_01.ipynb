{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backprop Workbook 01\n",
    "\n",
    "**For these questions, assume that an $x$ input has 1024 dimensions, that the first hidden layer should have $512$ units, a second layer has $256$ units, and that there are $10$ classes to choose from at the end.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cell to run for Latex commands**\n",
    "\n",
    "\\\\[\n",
    "\\newcommand{\\fpartial}[2]{\\frac{\\partial #1}{\\partial #2}}\n",
    "\\newcommand{\\grad}[1]{\\nabla #1}\n",
    "\\newcommand{\\softmax}[0]{\\text{SOFTMAX}}\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation to $z^{(3)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is $\\fpartial{}{x} \\log x$?**\n",
    "\n",
    "$\\frac{1}{x}$\n",
    "\n",
    "**What is the derivative $\\fpartial{}{x} g(f(x))$ in terms of $\\fpartial{}{x} f(x)$ and $\\fpartial{}{x} g(x)$? Recall that just like you can use the same variable name in two functions and they have nothing to do with each other, the $x$ in the $\\fpartial{}{x} f(x)$ isn't necessarily the same as the $x$ in $\\fpartial{}{x} g(x)$.**\n",
    "\n",
    "Chain rule.\n",
    "\n",
    "\\\\[\n",
    "\\fpartial{}{x} g\\left(f\\left(x\\right)\\right)\n",
    "=\n",
    "\\left(\\fpartial{}{y} g\\left(y\\right)\\right)\n",
    "    \\left(g\\left(x\\right)\\right)\n",
    "\\left(\\fpartial{}{x} f\\left(x\\right)\\right)\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We want to calculate $\\fpartial{}{z^{(3)}_i} CE_\\text{vector}(h^{(3)}, y)$. Recall that $h^{(3)} = \\text{SOFTMAX}\\left(z^{(3)}\\right)$. So before anything, let's write $CE_\\text{vector}(h^{(3)}, y)$ in terms of the $z^{(3)}$ by expanding the dot-product of $h^{(3)}$ and substituting the formula in terms of $z^{(3)}$.**\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "    CE\\left(h^{(3)}, y\\right)\n",
    "&=\n",
    "    -\\log h^{(3)} \\cdot y\n",
    "\\\\\n",
    "&=\n",
    "    -\\log \\sum_{i = 0}^{9} h^{(3)}_i y_i\n",
    "\\\\\n",
    "&=\n",
    "    -\\log \\sum_{i = 0}^{9}\n",
    "        y_i\n",
    "        \\frac{\n",
    "            \\exp\\left(z^{(3)}_i\\right)\n",
    "        }{\n",
    "            \\sum_{j=0}^9\n",
    "            \\exp\\left(z^{(3)}_j\\right)\n",
    "        }\n",
    "\\end{align}\n",
    "\\\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Next let the scalar value $y^*$ be the correct class. That is $y_i = 1$ exactly when $i = y^*$; else $y_i$ is zero.**\n",
    "\n",
    "**Notice then that all the terms of the sum don't matter except for $i = y^*$. So simplify the above formula**\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "    CE\\left(h^{(3)}, y\\right)\n",
    "&=\n",
    "    -\\log \\sum_{i = 0}^{9}\n",
    "        y_i\n",
    "        \\frac{\n",
    "            \\exp\\left(z^{(3)}_i\\right)\n",
    "        }{\n",
    "            \\sum_{j=0}^9\n",
    "            \\exp\\left(z^{(3)}_j\\right)\n",
    "        }\n",
    "\\\\\n",
    "&=\n",
    "    -\\log\\left(\n",
    "        y_{y^*}\n",
    "        \\frac{\n",
    "            \\exp\\left(z^{(3)}_{y^*}\\right)\n",
    "        }{\n",
    "            \\sum_{j=0}^9\n",
    "            \\exp\\left(z^{(3)}_j\\right)\n",
    "        }\n",
    "    \\right)\n",
    "\\\\\n",
    "&=\n",
    "    -\\log\\left(\n",
    "        \\frac{\n",
    "            \\exp\\left(z^{(3)}_{y*}\\right)\n",
    "        }{\n",
    "            \\sum_{j=0}^9\n",
    "            \\exp\\left(z^{(3)}_j\\right)\n",
    "        }\n",
    "    \\right)\n",
    "\\end{align}\n",
    "\\\\]\n",
    "\n",
    "Here we replace $y_{y^*}$ with 1 since this is the definition of the one-hot encoding.\n",
    "\n",
    "From here out, let's use $S := \\sum_{j=0}^9 \\exp\\left(z^{(3)}_j\\right)$ because I'm lazy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's calculate $\\fpartial{}{z^{(3)}_i} CE_\\text{vector}(h^{(3)}, y)$ for $i \\ne y^*$. First, it will help to simplify a log of a fraction into a difference of logs.**\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "    CE\\left(h^{(3)}, y\\right)\n",
    "&=\n",
    "    -\\log\\left(\n",
    "        \\frac{\n",
    "            \\exp\\left(z^{(3)}_{y*}\\right)\n",
    "        }{\n",
    "            \\sum_{j=0}^9\n",
    "            \\exp\\left(z^{(3)}_j\\right)\n",
    "        }\n",
    "    \\right)\n",
    "\\\\\n",
    "&=\n",
    "    -\\log \\left(\\exp\\left(z^{(3)}_{y*}\\right)\\right)\n",
    "    +\n",
    "    \\log \\left(\\sum_{j=0}^9 \\exp\\left(z^{(3)}_j\\right)\\right)\n",
    "\\\\\n",
    "&=\n",
    "    -z^{(3)}_{y*}\n",
    "    +\n",
    "    \\log \\left(\\sum_{j=0}^9 \\exp\\left(z^{(3)}_j\\right)\\right)\n",
    "\\end{align}\n",
    "\\\\]\n",
    "\n",
    "**Next, what is the derivative of the first term? Why?**\n",
    "\n",
    "Now, the first term is just $z^{(3)}_{y*}$, so if we differentiate with respect to some $z^{(3)}_i$ where $i$ is *not* the correct class, then this derivative is zero.\n",
    "\n",
    "Basically, a change to the other $z^{(3)}$ values doesn't change the numerator.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using the rule that the derivative of $\\log a$ wrt $a$ is $1/a$, and also the chain rule, do the first-step of the deriative of the second term wrt $z^{(3)}_i$.**\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "    \\fpartial{}{z^{(3)}_i}\n",
    "        \\log \\left(\\sum_{j=0}^9 \\exp\\left(z^{(3)}_j\\right)\\right)\n",
    "&=\n",
    "    \\frac{1}{\\sum_{j=0}^9 \\exp\\left(z^{(3)}_j\\right)}\n",
    "    \\fpartial{}{z^{(3)}_i}\n",
    "        \\left(\\sum_{j=0}^9 \\exp\\left(z^{(3)}_j\\right)\\right)\n",
    "\\end{align}\n",
    "\\\\]\n",
    "\n",
    "**Next, use the rule that the derivative of $e^a$ wrt $a$ is also $e^a$.**\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "    \\frac{1}{\\sum_{j=0}^9 \\exp\\left(z^{(3)}_j\\right)}\n",
    "    \\fpartial{}{z^{(3)}_i}\n",
    "        \\left(\\sum_{j=0}^9 \\exp\\left(z^{(3)}_j\\right)\\right)\n",
    "&=\n",
    "    \\frac{1}{\\sum_{j=0}^9 \\exp\\left(z^{(3)}_j\\right)}\n",
    "    \\exp\\left(z^{(3)}_i\\right)\n",
    "\\end{align}\n",
    "\\\\]\n",
    "\n",
    "**Finally, use the definition of $h^{(3)}_i = SOFTMAX(z^{(3)})_i$ to simplify this.**\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "    \\frac{1}{\\sum_{j=0}^9 \\exp\\left(z^{(3)}_j\\right)}\n",
    "    \\exp\\left(z^{(3)}_i\\right)\n",
    "&=\n",
    "    h^{(3)}_i\n",
    "\\end{align}\n",
    "\\\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, if $i = y^*$, what is the derivative of the first term of the difference of logs?**\n",
    "\n",
    "It is $-1.0$.\n",
    "\n",
    "**Does the formula for the derivative of the second difference term change?**\n",
    "\n",
    "No.\n",
    "\n",
    "**Thus, what is $\\fpartial{}{z^{(3)}_i} CE_\\text{vector}(h^{(3)}, y)$ when $i=y^*$?**\n",
    "\n",
    "$-1.0 + h^{3}_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The gradient $\\grad_{z^{(3)}} CE_\\text{vector}(h^{(3)}, y)$ is a vector. What are its entries?**\n",
    "\n",
    "\\\\[\n",
    "\\grad_{z^{(3)}} CE_\\text{vector}(h^{(3)}, y)_i\n",
    "=\n",
    "\\fpartial{}{z^{(3)}_i} CE_\\text{vector}(h^{(3)}, y)\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the vectorized formula for $\\grad_{z^{(3)}} CE_\\text{vector}(h^{(3)}, y)$?**\n",
    "\n",
    "\\\\[\n",
    "\\grad_{z^{(3)}} CE_\\text{vector}(h^{(3)}, y)\n",
    "=\n",
    "h^{(3)} - y\n",
    "\\\\]\n",
    "\n",
    "Where $y$ is the one-hot encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's do an intuition check. What entries of the gradient are positive? Which are negative? Why?**\n",
    "\n",
    "All entries except $y^*$ are positive, because increasing their log odds decreases the probability on the right answer. That increases the loss.\n",
    "\n",
    "Increasing $z^{(3)}_{y^*}$ increases the probability of the correct answer, so it reduces the loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backprop to $W^{(3)}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To update the weights $W^{(3)}$ we must calculate $\\grad_{W^{(3)}} CE_\\text{vector}(h^{(3)}, y)$. What is the shape of this \"2 dimensional gradient\"?**\n",
    "\n",
    "$(256, 10)$.\n",
    "\n",
    "**What does each entry $\\left(\\grad_{W^{(3)}} CE_\\text{vector}(h^{(3)}, y)\\right)_{i, j}$ mean?**\n",
    "\n",
    "It means how much the loss will change if we changed $W_{i, j}$ a little.\n",
    "\n",
    "**Reminder: which value in the second hidden layer does $W_{i, j}$ connect to which pre-activation in the third layer?**\n",
    "\n",
    "$h^{(2)}_i$ to $z^{(3)}_j$.\n",
    "\n",
    "**If for $j$ we have $\\fpartial{}{z^{(3)}_j} CE_\\text{vector}(h^{(3)}, y)$ is zero, what is $\\grad_{W^{(3)}} CE_\\text{vector}(h^{(3)}, y)$ for all $(i, j)$ for all $i$? Why?**\n",
    "\n",
    "It must be zero. Because changing any $W_{i, j}$ may change $z^{(3)}_j$, but we know that has no impact on the loss.\n",
    "\n",
    "**If for $i$ we have $h^{(2)}_i$ is zero, what is $\\grad_{W^{(3)}} CE_\\text{vector}(h^{(3)}, y)$ for all $(i, j)$ for all $j$? Why?**\n",
    "\n",
    "It must be zero. Changing any $W_{i, j}$ won't change $z^{(3)}_j$, because $z^{(3)}_j$ is a weighted sum of the $h^{(2)}_i$, but if a $h^{(2)}_i$ is zero, changing the associated weight doesn't change $z^{(3)}_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Given the above, what two \"forces\" does $\\left(\\grad_{W^{(3)}} CE_\\text{vector}(h^{(3)}, y)\\right)_{i, j}$ need to combine?**\n",
    "\n",
    "First, the amount that changing $W^{(3)}_{i, j}$ changes $z^{(3)}_j$.\n",
    "\n",
    "Second, the amount that changing $z^{(3)}_j$ changes the loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How do the two forces combine for $\\left(\\grad_{W^{(3)}} CE_\\text{vector}(h^{(3)}, y)\\right)_{i, j}$? Remember that $CE$ is a function of $z^{(3)}_j$ and $z^{(3)}_j$ is a function of $W^{(3)}_{i, j}$. Something something chain rule? First calculate $\\fpartial{}{W^{(3)}_{i, j}} z^{(3)}_j$.**\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "    \\fpartial{}{W^{(3)}_{i, j}} z^{(3)}_j\n",
    "&=\n",
    "    \\fpartial{}{W^{(3)}_{i, j}} \\sum_{i=0}^{256} h^{(2)}_i W_{i, j}\n",
    "\\\\\n",
    "&=\n",
    "    h^{(2)}_i\n",
    "\\end{align}\n",
    "\\\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Does it matter what $j$ is?\n",
    "2. Let's just calcualte the vector for $W^{(3)}_{:, j}$ for any $j$.\n",
    "3. What is the dimension of that vector.\n",
    "4. Something something outer product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (default)",
   "language": "python",
   "name": "conda-default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
